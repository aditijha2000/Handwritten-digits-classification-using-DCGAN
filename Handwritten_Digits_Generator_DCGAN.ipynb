{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Dependencies**"
      ],
      "metadata": {
        "id": "AXAARheLHZjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow imageio tensorflow.docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkXj1i9fHYUB",
        "outputId": "e7a9190c-26ab-462e-ee39-48851d5aada6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Collecting tensorflow.docs\n",
            "  Downloading tensorflow_docs-2024.2.5.73858-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.5/182.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Collecting astor (from tensorflow.docs)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from tensorflow.docs) (3.1.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from tensorflow.docs) (5.10.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from tensorflow.docs) (6.0.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->tensorflow.docs) (2.1.5)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow.docs) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow.docs) (4.19.2)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow.docs) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat->tensorflow.docs) (5.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow.docs) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow.docs) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow.docs) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->tensorflow.docs) (0.18.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->tensorflow.docs) (4.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: astor, tensorflow.docs\n",
            "Successfully installed astor-0.8.1 tensorflow.docs-2024.2.5.73858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWL16-DCHRTv"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the MNIST Handwritten digits datasets**"
      ],
      "metadata": {
        "id": "Ny4fSJTdLssn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3G65VyiIF63",
        "outputId": "dd6513cb-a865-43c7-a35f-bd6b634b9e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYlG2LoZMLjn",
        "outputId": "45def47e-411d-4b26-c193-d6b93b3c3383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5)/127.5   # Normalize the images to [-1, 1]"
      ],
      "metadata": {
        "id": "5AQJra-_MRne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 6000\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "w0Vir7n_Mp53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "x7eAq6H3M11c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kik8Bv4NHhJ",
        "outputId": "d5d70200-5259-46a5-8f6d-a80127953bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise = tf.random.normal([1, 100])"
      ],
      "metadata": {
        "id": "sFH5kUf6NlY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the model**"
      ],
      "metadata": {
        "id": "lctCrKWKOK7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator**"
      ],
      "metadata": {
        "id": "CO5YYo24OH-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Dense(7*7*256, use_bias = False, input_shape = (100,)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Reshape((7, 7, 256)))\n",
        "  assert model.output_shape == (None, 7, 7, 256)    #Note: None is the batch size\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(128, (5,5), strides = (1,1), padding = 'same', use_bias = False))\n",
        "  assert model.output_shape == (None, 7, 7, 128)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(64, (5, 5), strides = (2, 2), padding = 'same', use_bias = False))\n",
        "  assert model.output_shape == (None, 14, 14, 64)\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.LeakyReLU())\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(1, (5, 5), strides = (2, 2), padding = 'same', use_bias = False, activation = 'tanh'))\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "nQFtpDOxOF46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the untrained generator to generate an image from random noise\n",
        "\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "zGQtPzAbcY-O",
        "outputId": "ae5bfca2-4949-45c8-a1b1-11c945e97661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7d5ee62b6cb0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discriminator**"
      ],
      "metadata": {
        "id": "JpBeJK0yiFc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_discriminator_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (5, 5), strides = (2, 2), padding='same', input_shape = [28, 28, 1]))\n",
        "\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Conv2D(128, (5, 5), strides = (2, 2), padding = 'same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "Tbfr-TS2dEna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the untrained discriminator to predict the generated image\n",
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print(decision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbbdP7MWi91s",
        "outputId": "2bce0aa9-2d07-4c54-a3ab-6ba1446777d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.00019342]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss and Optimizer**"
      ],
      "metadata": {
        "id": "vIOyEMytjeGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
      ],
      "metadata": {
        "id": "KCL5Dv-0jQ5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discriminator Loss**"
      ],
      "metadata": {
        "id": "e4fBRCkIjxcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones.like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros.like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "Hj_tqtqujsaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator Loss**"
      ],
      "metadata": {
        "id": "mgDDX8MAkpae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "  loss = cross_entropy(tf.ones.like(fake_output), fake_output)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "Pq1mKWS1kWEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The discriminator and generator optimizers are different as we are training two networks simulatneously."
      ],
      "metadata": {
        "id": "9JjDHVgLlRZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "mN2YE_u_k6vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the checkpoints**"
      ],
      "metadata": {
        "id": "TObKM3FGlptr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir =  './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "metadata": {
        "id": "HTTIEdMIloCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the training loop**"
      ],
      "metadata": {
        "id": "HIdBani5mk1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "noise_dim = 100\n",
        "num_of_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF\n",
        "seed = tf.random.normal([num_of_examples_to_generate, noise_dim])"
      ],
      "metadata": {
        "id": "zi8Z2TO6mjGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images and fake images. The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ],
      "metadata": {
        "id": "ar-bjRBZnk0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be compiled\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "\n",
        "    real_output = discriminator(images, training = True)\n",
        "    fake_output = discriminator(generated_images, training = True)\n",
        "\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  # after calculating the gradients the gradients are passed onto the optimizers for them to update the weights\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "metadata": {
        "id": "xl6S8xOTnWbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epoch+1, seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint.prefix)\n",
        "\n",
        "    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time().start()))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator, epochs, seed)"
      ],
      "metadata": {
        "id": "YtMw6RPHxqhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate and save images**"
      ],
      "metadata": {
        "id": "VQUXQY2Hoej6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False\n",
        "  # This is so all layers run in inference mode (batchnorm)\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap = 'gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.savefig('image at epoch {:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Lp-CX6pFodZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "84gjXZZMqFK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the train() method defined above to train the generator and discriminator simulatneously. Note, training GANs can be tricky. It is important that the generator and discriminator do not overpower each other.\n",
        "\n",
        "At the beginning of the training, the generated images look like random noise. As training processes, the generated digits will look increasingly real. After abput 50 epochs, they resemble MNIST digits."
      ],
      "metadata": {
        "id": "j9SMhS9iqLyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "id": "yV5dd5nuqIPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "id": "PHgl8q2ErOB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image at epoch {:04d}.png'.format(epoch_no))"
      ],
      "metadata": {
        "id": "JyzlpEcnrazr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_image(EPOCHS)"
      ],
      "metadata": {
        "id": "B7z0dHEDru4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `imageio` to create an animated gif using the images saved during training."
      ],
      "metadata": {
        "id": "bCfsR78Qr03-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ],
      "metadata": {
        "id": "8oV2EFohrzCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ],
      "metadata": {
        "id": "KlttCSbht-bS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}